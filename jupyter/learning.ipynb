{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b795cee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if sys.platform == 'win32':\n",
    "    file_path = 'C:\\\\videos\\\\TheGreat_2_2001_169_2398_ProRes422HQ_ENG20_ENG51_BPO20_BPO51_Primary_A17913780.mov'\n",
    "elif sys.platform == 'linux':\n",
    "    file_path = '/mnt/c/videos/TheGreat_2_2001_169_2398_ProRes422HQ_ENG20_ENG51_BPO20_BPO51_Primary_A17913780.mov'\n",
    "else:\n",
    "    file_path = '/Users/leandro.correia/Documents/videos/TheGreat_2_2001_169_2398_ProRes422HQ_ENG20_ENG51_BPO20_BPO51_Primary_A17913780.mov'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a52dad",
   "metadata": {},
   "source": [
    "## Using mediainfo to load media technical information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bf4b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymediainfo import MediaInfo\n",
    "import numpy as np\n",
    "\n",
    "# Extract media information\n",
    "media_info = MediaInfo.parse(file_path)\n",
    "\n",
    "# Initialize variables to store audio track count and metadata\n",
    "audio_tracks = []\n",
    "audio_metadata = []\n",
    "\n",
    "# Iterate through tracks to find audio tracks\n",
    "for track in media_info.tracks:\n",
    "    if track.track_type == \"Audio\":\n",
    "        audio_tracks.append(track)\n",
    "        audio_metadata.append(track.to_data())\n",
    "\n",
    "# Output the number of audio tracks and their metadata\n",
    "print(f\"Number of audio tracks: {len(audio_tracks)}\")\n",
    "print(\"Audio track metadata:\")\n",
    "for idx, metadata in enumerate(audio_metadata, start=1):\n",
    "    print(f\"Track {idx}: {metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd7cefa",
   "metadata": {},
   "source": [
    "## The mediainfo audio structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18081088",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in audio_metadata[0].items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774ca417",
   "metadata": {},
   "source": [
    "## Important properties to check the quality of data importer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46d4d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_metadata[0].get('format') # PCM\n",
    "audio_metadata[0].get('format_settings__endianness') # Little\n",
    "audio_metadata[0].get('format_settings__wrapping_mode') # Frame (AES)\n",
    "audio_metadata[0].get('codec_id') # 0D01030102060300\n",
    "audio_metadata[0].get('duration') # 691558\n",
    "audio_metadata[0].get('bit_rate_mode') # CBR\n",
    "audio_metadata[0].get('bit_rate') # 1152000\n",
    "audio_metadata[0].get('samples_per_frame') # 1601.6\n",
    "audio_metadata[0].get('sampling_rate') # 48000\n",
    "audio_metadata[0].get('samples_count') # 33194784\n",
    "audio_metadata[0].get('frame_rate') # 29.970\n",
    "audio_metadata[0].get('frame_count') # 20726\n",
    "audio_metadata[0].get('bit_depth') # 24\n",
    "audio_metadata[0].get('delay_dropframe') # Yes\n",
    "audio_metadata[0].get('stream_size') # 99584352\n",
    "audio_metadata[0].get('blockalignment') # 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3799f56f",
   "metadata": {},
   "source": [
    "## Extract audio track\n",
    "\n",
    "#### using memory extract data from video and open raw data into byte array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284c8507",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "from extractor.audio_ffmpeg import AudioFFmpegExtractor\n",
    "\n",
    "sr = 16000\n",
    "\n",
    "ffmpeg_extractor = AudioFFmpegExtractor()\n",
    "\n",
    "buffer = ffmpeg_extractor.extract(file_path, 0, int(sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c0fb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(buffer), type(buffer[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f69fb7",
   "metadata": {},
   "source": [
    "## get item array size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a55ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = type(buffer[0])\n",
    "sample_size_bytes = np.dtype(dtype).itemsize\n",
    "sample_size_bits = sample_size_bytes * 8\n",
    "print(dtype, \"sample size in bytes:\", sample_size_bytes, \"bits:\", sample_size_bits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245ebfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_bitrate(sr, bits, ch, ms):\n",
    "    bit_rate = (sr * bits * ch)\n",
    "    return bit_rate/1000\n",
    "\n",
    "def check_duration(raw_data, sr):\n",
    "    duration_seconds = len(raw_data) / sr\n",
    "    minutes = int(duration_seconds // 60)\n",
    "    seconds = int(duration_seconds % 60)\n",
    "    return f\"{minutes}:{seconds:02d}\"\n",
    "    \n",
    "\n",
    "total_duration = audio_metadata[0].get('duration')\n",
    "\n",
    "print(\"Bitrate in kbps:\", check_bitrate(sr, sample_size_bits, 1, total_duration))\n",
    "print(\"Duration in millis:\", check_duration(buffer, sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b47c716",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_flat_buffer = buffer.flatten().astype(np.float32) / 32768.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a151f9",
   "metadata": {},
   "source": [
    "## Load data into librosa to draw mel spectogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bcaeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate a mel spectrogram\n",
    "S = librosa.feature.melspectrogram(y=norm_flat_buffer, sr=sr, n_mels=128, fmax=sr // 2)\n",
    "\n",
    "# Convert to log scale (dB)\n",
    "S_dB = librosa.power_to_db(S, ref=np.max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16890847",
   "metadata": {},
   "source": [
    "## using matplotlib to draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdcdc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the mel spectrogram\n",
    "plt.figure(figsize=(10, 4))\n",
    "librosa.display.specshow(S_dB, sr=sr, x_axis='time', y_axis='mel', fmax=sr // 2)\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title('Mel Spectrogram')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c8e3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa.display\n",
    "\n",
    "# Plot the waveform\n",
    "plt.figure(figsize=(10, 4))\n",
    "librosa.display.waveshow(norm_flat_buffer, sr=sr, alpha=0.5)\n",
    "plt.title('Waveform')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bf0ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_waveforms(data_list, sr):\n",
    "    \"\"\"\n",
    "    Draw a list of waveforms in a pyplot subplot format.\n",
    "\n",
    "    Args:\n",
    "        data_list (list of np.ndarray): List of audio data arrays.\n",
    "        sr (int): Sampling rate of the audio data.\n",
    "    \"\"\"\n",
    "    num_waveforms = len(data_list)\n",
    "    rows = (num_waveforms + 1) // 2  # Two waveforms per row\n",
    "\n",
    "    plt.figure(figsize=(12, rows * 3))\n",
    "\n",
    "    for idx, data in enumerate(data_list):\n",
    "        plt.subplot(rows, 2, idx + 1)\n",
    "        librosa.display.waveshow(data.get('data'), sr=sr, alpha=0.5)\n",
    "        plt.title('Waveform {} layout {}'.format(idx, data.get('channel_layout')))\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel('Amplitude')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a038ad",
   "metadata": {},
   "source": [
    "## Drawing and expose silent tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2416b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "from extractor.audio_ffmpeg import AudioFFmpegExtractor\n",
    "from pymediainfo import MediaInfo\n",
    "\n",
    "\n",
    "SAMPLING_RATE = 16000\n",
    "\n",
    "# Extract media information\n",
    "media_info = MediaInfo.parse(file_path)\n",
    "\n",
    "# Initialize variables to store audio track count and metadata\n",
    "audio_tracks = []\n",
    "\n",
    "ffmpeg_extractor = AudioFFmpegExtractor()\n",
    "# Iterate through tracks to find audio tracks\n",
    "for track in media_info.tracks:\n",
    "    if track.track_type == \"Audio\":\n",
    "        buffer = ffmpeg_extractor.extract(file_path, track.to_data().get('stream_identifier'), SAMPLING_RATE)\n",
    "        \n",
    "        norm_flat_buffer = buffer.flatten().astype(np.float32) / 32768.0\n",
    "        audio_tracks.append({\n",
    "            'id': track.to_data().get('stream_identifier'),\n",
    "            'data': norm_flat_buffer,\n",
    "            'channel_layout': track.to_data().get('channel_layout')\n",
    "            })\n",
    "\n",
    "        \n",
    "draw_waveforms(audio_tracks, SAMPLING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab31ffa",
   "metadata": {},
   "source": [
    "## Compare stereo against 5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e581a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for audio in audio_tracks:\n",
    "    print(audio.get('id'), audio.get('channel_layout'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda8790d",
   "metadata": {},
   "source": [
    "## Compare channels using correlation\n",
    "Check if L and Lt (and R and Rt) are highly correlated (≈1.0)\n",
    "\n",
    "If correlation > 0.99, they’re probably duplicates or matrixed from the same source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6446ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "\n",
    "get_track_by_layout = lambda layout: next(track for track in audio_tracks if track.get('channel_layout') == layout)\n",
    "\n",
    "lt = get_track_by_layout('Lt').get('data')\n",
    "rt = get_track_by_layout('Rt').get('data')\n",
    "l = get_track_by_layout('L').get('data')\n",
    "r = get_track_by_layout('R').get('data')\n",
    "\n",
    "corr_l, _ = pearsonr(lt, l)  # Compare Lt vs L\n",
    "corr_r, _ = pearsonr(rt, r)  # Compare Rt vs R\n",
    "\n",
    "print(f\"Correlation Lt vs L: {corr_l:.3f}\")\n",
    "print(f\"Correlation Rt vs R: {corr_r:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4df2ca",
   "metadata": {},
   "source": [
    "# Comparing Left Total with Right Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928f74e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_lt_rt, _ = pearsonr(lt, rt)\n",
    "print(f\"Correlation Lt vs Rt: {corr_lt_rt:.3f}\")\n",
    "\n",
    "corr_l_r, _ = pearsonr(l, r)\n",
    "print(f\"Correlation left vs right: {corr_l_r:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933708aa",
   "metadata": {},
   "source": [
    "## Checking low effects frequency\n",
    "\n",
    "If the plot shows most energy < 120 Hz, then it's a proper LFE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04127bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.fft import rfft, rfftfreq\n",
    "\n",
    "# lfe: numpy array of LFE channel\n",
    "sample_rate = 44100  # or your actual rate\n",
    "\n",
    "lfe = get_track_by_layout('LFE').get('data')\n",
    "\n",
    "N = len(lfe)\n",
    "yf = rfft(lfe)\n",
    "xf = rfftfreq(N, 1 / sample_rate)\n",
    "\n",
    "plt.plot(xf, np.abs(yf))\n",
    "plt.xlim(0, 500)  # Focus on bass range\n",
    "plt.title(\"LFE Frequency Content\")\n",
    "plt.xlabel(\"Hz\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b92dba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import butter, filtfilt\n",
    "\n",
    "def lowpass_filter(data, cutoff, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return filtfilt(b, a, data)\n",
    "\n",
    "filtered_lfe = lowpass_filter(lfe, 120, sample_rate)\n",
    "plt.plot(xf, np.abs(rfft(filtered_lfe)))\n",
    "plt.xlim(0, 500)  # Focus on bass range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc077b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = get_track_by_layout('Ls').get('data')\n",
    "rs = get_track_by_layout('Rs').get('data')\n",
    "\n",
    "corr_ls_l, _ = pearsonr(ls, l)\n",
    "corr_rs_r, _ = pearsonr(rs, r)\n",
    "\n",
    "print(f\"Correlation Ls vs L: {corr_ls_l:.3f}\")\n",
    "print(f\"Correlation Rs vs R: {corr_rs_r:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c551ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "c = get_track_by_layout('C').get('data')\n",
    "\n",
    "\n",
    "signals = [l, r, c, lfe, ls, rs]\n",
    "labels = ['L', 'R', 'C', 'LFE', 'Ls', 'Rs']\n",
    "\n",
    "n = len(signals)\n",
    "cols = 2\n",
    "rows = (n + 1) // cols\n",
    "\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(12, 3 * rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (signal, label) in enumerate(zip(signals, labels)):\n",
    "    D = librosa.amplitude_to_db(np.abs(librosa.stft(signal)), ref=np.max)\n",
    "    img = librosa.display.specshow(D, sr=sample_rate, x_axis='time', y_axis='log', ax=axes[i])\n",
    "    axes[i].set_title(f\"Spectrogram: {label}\")\n",
    "    fig.colorbar(img, ax=axes[i], format=\"%+2.0f dB\")\n",
    "    axes[i].label_outer()\n",
    "\n",
    "# Hide any unused subplots\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chunk-norris",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
