{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87a52dad",
   "metadata": {},
   "source": [
    "## Using mediainfo to load media technical information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bf4b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymediainfo import MediaInfo\n",
    "import numpy as np\n",
    "\n",
    "file_path = 'C:\\\\videos\\\\6230046.mxf'\n",
    "\n",
    "# Extract media information\n",
    "media_info = MediaInfo.parse(file_path)\n",
    "\n",
    "# Initialize variables to store audio track count and metadata\n",
    "audio_tracks = []\n",
    "audio_metadata = []\n",
    "\n",
    "# Iterate through tracks to find audio tracks\n",
    "for track in media_info.tracks:\n",
    "    if track.track_type == \"Audio\":\n",
    "        audio_tracks.append(track)\n",
    "        audio_metadata.append(track.to_data())\n",
    "\n",
    "# Output the number of audio tracks and their metadata\n",
    "print(f\"Number of audio tracks: {len(audio_tracks)}\")\n",
    "print(\"Audio track metadata:\")\n",
    "for idx, metadata in enumerate(audio_metadata, start=1):\n",
    "    print(f\"Track {idx}: {metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd7cefa",
   "metadata": {},
   "source": [
    "## The mediainfo audio structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18081088",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in audio_metadata[0].items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774ca417",
   "metadata": {},
   "source": [
    "## Important properties to check the quality of data importer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46d4d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_metadata[0].get('format') # PCM\n",
    "audio_metadata[0].get('format_settings__endianness') # Little\n",
    "audio_metadata[0].get('format_settings__wrapping_mode') # Frame (AES)\n",
    "audio_metadata[0].get('codec_id') # 0D01030102060300\n",
    "audio_metadata[0].get('duration') # 691558\n",
    "audio_metadata[0].get('bit_rate_mode') # CBR\n",
    "audio_metadata[0].get('bit_rate') # 1152000\n",
    "audio_metadata[0].get('samples_per_frame') # 1601.6\n",
    "audio_metadata[0].get('sampling_rate') # 48000\n",
    "audio_metadata[0].get('samples_count') # 33194784\n",
    "audio_metadata[0].get('frame_rate') # 29.970\n",
    "audio_metadata[0].get('frame_count') # 20726\n",
    "audio_metadata[0].get('bit_depth') # 24\n",
    "audio_metadata[0].get('delay_dropframe') # Yes\n",
    "audio_metadata[0].get('stream_size') # 99584352\n",
    "audio_metadata[0].get('blockalignment') # 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3799f56f",
   "metadata": {},
   "source": [
    "## Extract audio track\n",
    "\n",
    "#### using memory extract data from video and open raw data into byte array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284c8507",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "from extractor.audio_ffmpeg import AudioFFmpegExtractor\n",
    "\n",
    "sr = 16000\n",
    "\n",
    "ffmpeg_extractor = AudioFFmpegExtractor()\n",
    "\n",
    "buffer = ffmpeg_extractor.extract(file_path, 0, int(sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c0fb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(buffer), type(buffer[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f69fb7",
   "metadata": {},
   "source": [
    "## get item array size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a55ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = type(buffer[0])\n",
    "sample_size_bytes = np.dtype(dtype).itemsize\n",
    "sample_size_bits = sample_size_bytes * 8\n",
    "print(dtype, \"sample size in bytes:\", sample_size_bytes, \"bits:\", sample_size_bits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245ebfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_bitrate(sr, bits, ch, ms):\n",
    "    bit_rate = (sr * bits * ch)\n",
    "    return bit_rate/1000\n",
    "\n",
    "def check_duration(raw_data, sr):\n",
    "    duration_seconds = len(raw_data) / sr\n",
    "    minutes = int(duration_seconds // 60)\n",
    "    seconds = int(duration_seconds % 60)\n",
    "    return f\"{minutes}:{seconds:02d}\"\n",
    "    \n",
    "\n",
    "total_duration = audio_metadata[0].get('duration')\n",
    "\n",
    "print(\"Bitrate in kbps:\", check_bitrate(sr, sample_size_bits, 1, total_duration))\n",
    "print(\"Duration in millis:\", check_duration(buffer, sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b47c716",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_flat_buffer = buffer.flatten().astype(np.float32) / 32768.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a151f9",
   "metadata": {},
   "source": [
    "## Load data into librosa to draw mel spectogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bcaeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate a mel spectrogram\n",
    "S = librosa.feature.melspectrogram(y=norm_flat_buffer, sr=sr, n_mels=128, fmax=sr // 2)\n",
    "\n",
    "# Convert to log scale (dB)\n",
    "S_dB = librosa.power_to_db(S, ref=np.max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16890847",
   "metadata": {},
   "source": [
    "## using matplotlib to draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdcdc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the mel spectrogram\n",
    "plt.figure(figsize=(10, 4))\n",
    "librosa.display.specshow(S_dB, sr=sr, x_axis='time', y_axis='mel', fmax=sr // 2)\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title('Mel Spectrogram')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c8e3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa.display\n",
    "\n",
    "# Plot the waveform\n",
    "plt.figure(figsize=(10, 4))\n",
    "librosa.display.waveshow(norm_flat_buffer, sr=sr, alpha=0.5)\n",
    "plt.title('Waveform')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bf0ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_waveforms(data_list, sr):\n",
    "    \"\"\"\n",
    "    Draw a list of waveforms in a pyplot subplot format.\n",
    "\n",
    "    Args:\n",
    "        data_list (list of np.ndarray): List of audio data arrays.\n",
    "        sr (int): Sampling rate of the audio data.\n",
    "    \"\"\"\n",
    "    num_waveforms = len(data_list)\n",
    "    rows = (num_waveforms + 1) // 2  # Two waveforms per row\n",
    "\n",
    "    plt.figure(figsize=(12, rows * 3))\n",
    "\n",
    "    for idx, data in enumerate(data_list):\n",
    "        plt.subplot(rows, 2, idx + 1)\n",
    "        librosa.display.waveshow(data, sr=sr, alpha=0.5)\n",
    "        plt.title(f'Waveform {idx}')\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel('Amplitude')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a038ad",
   "metadata": {},
   "source": [
    "## Drawing and expose silent tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2416b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "from extractor.audio_ffmpeg import AudioFFmpegExtractor\n",
    "from pymediainfo import MediaInfo\n",
    "\n",
    "\n",
    "SAMPLING_RATE = 16000\n",
    "file_path = 'C:\\\\videos\\\\6230046.mxf'\n",
    "\n",
    "# Extract media information\n",
    "media_info = MediaInfo.parse(file_path)\n",
    "\n",
    "# Initialize variables to store audio track count and metadata\n",
    "audio_tracks = []\n",
    "\n",
    "ffmpeg_extractor = AudioFFmpegExtractor()\n",
    "# Iterate through tracks to find audio tracks\n",
    "for track in media_info.tracks:\n",
    "    if track.track_type == \"Audio\":\n",
    "        buffer = ffmpeg_extractor.extract(file_path, track.to_data().get('stream_identifier'), SAMPLING_RATE)\n",
    "        norm_flat_buffer = buffer.flatten().astype(np.float32) / 32768.0\n",
    "        audio_tracks.append(norm_flat_buffer)\n",
    "\n",
    "        \n",
    "draw_waveforms(audio_tracks, SAMPLING_RATE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chunk-norris",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
