{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73f074c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if sys.platform == 'win32':\n",
    "    file_path = 'C:\\\\videos\\\\TheGreat_2_2001_169_2398_ProRes422HQ_ENG20_ENG51_BPO20_BPO51_Primary_A17913780.mov'\n",
    "elif sys.platform == 'linux':\n",
    "    file_path = '/mnt/c/videos/TheGreat_2_2001_169_2398_ProRes422HQ_ENG20_ENG51_BPO20_BPO51_Primary_A17913780.mov'\n",
    "else:\n",
    "    file_path = '/Users/leandro.correia/Documents/videos/TheGreat_2_2001_169_2398_ProRes422HQ_ENG20_ENG51_BPO20_BPO51_Primary_A17913780.mov'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600f65f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymediainfo import MediaInfo\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Extract media information\n",
    "media_info = MediaInfo.parse(file_path)\n",
    "\n",
    "# Initialize variables to store audio track count and metadata\n",
    "audio_tracks = []\n",
    "audio_metadata = []\n",
    "\n",
    "# Iterate through tracks to find audio tracks\n",
    "for track in media_info.tracks:\n",
    "    if track.track_type == \"Audio\":\n",
    "        audio_tracks.append(track)\n",
    "        audio_metadata.append(track.to_data())\n",
    "\n",
    "# Output the number of audio tracks and their metadata\n",
    "print(f\"Number of audio tracks: {len(audio_tracks)}\")\n",
    "print(\"Audio track metadata:\")\n",
    "for idx, metadata in enumerate(audio_metadata, start=1):\n",
    "    print(f\"Track {idx}: {metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e387abb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "from extractor.audio_ffmpeg import AudioFFmpegExtractor\n",
    "from pymediainfo import MediaInfo\n",
    "\n",
    "\n",
    "SAMPLING_RATE = 16000\n",
    "\n",
    "# Extract media information\n",
    "media_info = MediaInfo.parse(file_path)\n",
    "\n",
    "# Initialize variables to store audio track count and metadata\n",
    "audio_tracks = []\n",
    "\n",
    "ffmpeg_extractor = AudioFFmpegExtractor()\n",
    "# Iterate through tracks to find audio tracks\n",
    "for track in media_info.tracks:\n",
    "    if track.track_type == \"Audio\":\n",
    "        buffer = ffmpeg_extractor.extract(file_path, track.to_data().get('stream_identifier'), SAMPLING_RATE)\n",
    "        \n",
    "        norm_flat_buffer = buffer.flatten().astype(np.float32) / 32768.0\n",
    "        audio_tracks.append({\n",
    "            'id': track.to_data().get('stream_identifier'),\n",
    "            'data': norm_flat_buffer,\n",
    "            'channel_layout': track.to_data().get('channel_layout')\n",
    "            })\n",
    "\n",
    "\n",
    "for audio in audio_tracks:\n",
    "    print(audio.get('id'), audio.get('channel_layout'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0908817f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple\n",
    "from datetime import timedelta\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Silence:\n",
    "    start: timedelta\n",
    "    duration: timedelta\n",
    "    index_start: int\n",
    "    index_end: int\n",
    "\n",
    "\n",
    "class SilenceProcessor:\n",
    "    def is_silence(self, amplitude: float, threshold_db: int) -> bool:\n",
    "        if amplitude == 0:\n",
    "            return True\n",
    "        dB = 20 * np.log10(abs(amplitude))\n",
    "        return dB < threshold_db\n",
    "\n",
    "    def get_silence_duration(\n",
    "        self,\n",
    "        samples: np.ndarray,  # 1D or 2D (channels x samples or interleaved)\n",
    "        sample_rate: int,\n",
    "        channels: int,\n",
    "        min_silence: timedelta,\n",
    "        silence_threshold_db: int = -40\n",
    "    ) -> Tuple[timedelta, timedelta, int, int]:\n",
    "\n",
    "        # If stereo or multi-channel interleaved, convert to mono by averaging channels\n",
    "        if samples.ndim == 2:\n",
    "            samples = samples.mean(axis=0)\n",
    "\n",
    "        threshold = 10 ** (silence_threshold_db / 20)\n",
    "\n",
    "        counter_start = -1\n",
    "        counter_length = 0\n",
    "\n",
    "        samples_per_ms = sample_rate / 1000.0\n",
    "        count_min_silence = int(min_silence.total_seconds() * sample_rate)\n",
    "\n",
    "        for i, sample in enumerate(samples):\n",
    "            if self.is_silence(sample, silence_threshold_db):\n",
    "                if counter_start == -1:\n",
    "                    counter_start = i\n",
    "                counter_length += 1\n",
    "            else:\n",
    "                if counter_start != -1:\n",
    "                    if counter_length >= count_min_silence:\n",
    "                        break\n",
    "                    counter_start = -1\n",
    "                    counter_length = 0\n",
    "\n",
    "        if counter_start == -1:\n",
    "            return timedelta(milliseconds=-1), timedelta(milliseconds=-1), -1, -1\n",
    "\n",
    "        silence_start_ms = counter_start / samples_per_ms\n",
    "        silence_duration_ms = counter_length / samples_per_ms\n",
    "\n",
    "        return (\n",
    "            timedelta(milliseconds=silence_start_ms),\n",
    "            timedelta(milliseconds=silence_duration_ms),\n",
    "            counter_start,\n",
    "            counter_length\n",
    "        )\n",
    "\n",
    "    def get_silence(\n",
    "        self,\n",
    "        samples: np.ndarray,\n",
    "        sample_rate: int,\n",
    "        channels: int,\n",
    "        min_silence: timedelta,\n",
    "        silence_threshold_db: int = -40\n",
    "    ) -> Silence:\n",
    "        start, duration, index_start, index_count = self.get_silence_duration(\n",
    "            samples, sample_rate, channels, min_silence, silence_threshold_db\n",
    "        )\n",
    "        return Silence(\n",
    "            start=start,\n",
    "            duration=duration,\n",
    "            index_start=index_start,\n",
    "            index_end=index_start + index_count - 1\n",
    "        )\n",
    "\n",
    "    def get_all_silences(\n",
    "        self,\n",
    "        samples: np.ndarray,\n",
    "        sample_rate: int,\n",
    "        channels: int,\n",
    "        min_silence: timedelta,\n",
    "        silence_threshold_db: int = -40\n",
    "    ) -> List[Silence]:\n",
    "        silences = []\n",
    "        slicer = 0\n",
    "        time_since_start = timedelta(0)\n",
    "\n",
    "        while slicer < len(samples):\n",
    "            sub_samples = samples[slicer:]\n",
    "            start, duration, index_start, index_count = self.get_silence_duration(\n",
    "                sub_samples, sample_rate, channels, min_silence, silence_threshold_db\n",
    "            )\n",
    "\n",
    "            if start.total_seconds() < 0:\n",
    "                break\n",
    "\n",
    "            actual_start = time_since_start + start\n",
    "            silence = Silence(\n",
    "                start=actual_start,\n",
    "                duration=duration,\n",
    "                index_start=slicer + index_start,\n",
    "                index_end=slicer + index_start + index_count - 1\n",
    "            )\n",
    "            silences.append(silence)\n",
    "\n",
    "            time_since_start += start + duration\n",
    "            slicer += index_start + index_count\n",
    "\n",
    "        return silences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5e9e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_bytes = audio_tracks[0].get('data')\n",
    "type(raw_bytes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49839fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = SilenceProcessor()\n",
    "silences = processor.get_all_silences(\n",
    "    audio_tracks[0].get('data'),\n",
    "    sample_rate=16000,\n",
    "    channels=1,\n",
    "    min_silence=timedelta(milliseconds=500),\n",
    "    silence_threshold_db=-40\n",
    ")\n",
    "\n",
    "for silence in silences:\n",
    "    print(silence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f1b483",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, len(silences)):\n",
    "    prev_end = silences[i-1].start + silences[i-1].duration\n",
    "    curr_start = silences[i].start\n",
    "    distance = (curr_start - prev_end).total_seconds()\n",
    "    print(f\"Distance between silence {i-1} and {i}: {distance:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf4c74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "audio_data = audio_tracks[0].get('data')\n",
    "time_axis = np.arange(len(audio_data)) / SAMPLING_RATE\n",
    "\n",
    "plt.figure(figsize=(15, 4))\n",
    "plt.plot(time_axis, audio_data, label='Audio waveform', alpha=0.7)\n",
    "\n",
    "for silence in silences:\n",
    "    start_sec = silence.start.total_seconds()\n",
    "    end_sec = (silence.start + silence.duration).total_seconds()\n",
    "    plt.axvspan(start_sec, end_sec, color='red', alpha=0.3, label='Silence' if 'Silence' not in plt.gca().get_legend_handles_labels()[1] else \"\")\n",
    "\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title('Audio waveform with detected silences')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chunk-norris",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
